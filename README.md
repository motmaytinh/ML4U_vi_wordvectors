# Pre-trained word vectors for Vietnamese

This project contains embedding for 174080 Vietnamese unique words from a corpus of 100,000 top documents from Vietnamese Wikipedia. Note that all words are tokenized words.

## Requirements
* gensim > =0.13.1 (for Word2Vec)
<!--* fastText (for [fasttext](https://github.com/facebookresearch/fastText))-->
	
## Background / References
* Check [this](https://en.wikipedia.org/wiki/Word_embedding) to know what word embedding is.
* Check [this](https://en.wikipedia.org/wiki/Word2vec) to quickly get a picture of Word2vec.
<!--* Check [this](https://github.com/facebookresearch/fastText) to install fastText.-->

## Pre-trained models
Download the [ML4U vi embedding](https://drive.google.com/open?id=1-2c3QWQ8XzSABjsYzMVUdNEE0fOspYcg).
